---
categories:  
- ""
- ""
date: "2022-09-13"
description: ""
draft: false
image: bikes.jpg
keywords: ""
slug: excess_bike_rentals # slug is the shorthand URL address... no spaces plz
title: Excess rentals in TfL bike sharing
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(wbstats)
library(countrycode)
library(patchwork)
library(gganimate)
```

Recall the TfL data on how many bikes were hired every single day. We
can get the latest data by running the following

```{r, get_tfl_data, cache=TRUE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))
```

We can easily create a facet grid that plots bikes hired by month and
year since 2015

```{r tfl_month_year_grid, echo=FALSE, out.width="100%"}
knitr::include_graphics("/img/bikes1.png",error=FALSE)
```

However, the challenge I want you to work on is to reproduce the
following two graphs.

```{r tfl_absolute_monthly_change, echo=FALSE, out.width="100%"}
knitr::include_graphics("/img/bikes2.png",error=FALSE)
```

The second one looks at percentage changes from the expected level of
weekly rentals. The two grey shaded rectangles correspond to Q2 (weeks
14-26) and Q4 (weeks 40-52).

```{r tfl_percent_change, echo=FALSE, out.width="100%"}
knitr::include_graphics("/img/bikes3.png",error=FALSE)
```

```{r Chlng1_bike_by_month}
bike_monthly_avg<-bike%>%
  filter(year %in% c(2017, 2018, 2019, 2020, 2021, 2022))%>%
  group_by(year, month)%>%
  summarise(monthly_avg=mean(bikes_hired))%>%
  ungroup()%>%
  add_row(year=2022, month="Sep")%>%
  add_row(year=2022, month="Oct")%>%
  add_row(year=2022, month="Nov")%>%
  add_row(year=2022, month="Dec")%>%
  group_by(year, month)%>%
  mutate(date=as.Date(paste("01", month, toString(year), sep="/"), "%d/%b/%Y"))

bike_monthly_avg_across_years<-bike%>%
  filter(year %in% c(2016, 2017, 2018, 2019))%>%
  group_by(month)%>%
  summarise(monthly_avg_across_years=mean(bikes_hired))

bike_monthly_avg <-bike_monthly_avg%>% 
  inner_join(bike_monthly_avg_across_years, by = "month")%>%
  mutate(monthly_avg_across_years=ifelse(year==2022 & (month %in% c("Sep", "Oct", "Nov", "Dec")), NA, monthly_avg_across_years))
  
bike_monthly_avg
```

```{r Chlng1_plot1, warning=FALSE}
library(ggbraid)

ggplot(bike_monthly_avg,aes(x=date))+geom_line(aes(y=monthly_avg))+geom_line(aes(y=monthly_avg_across_years), color="blue", size=1)+facet_wrap(~year, scales="free_x", nrow=2) + scale_x_date(date_breaks = "1 month", date_labels = "%b")+
  geom_braid(aes(ymin=monthly_avg, ymax=monthly_avg_across_years, fill=monthly_avg>monthly_avg_across_years))+theme(legend.position="none")+
  labs(title = "Monthly changes in TfL bike rentals",
       subtitle = "Change from monthly average shown in blue and calculated between 2016-2019", 
       caption = "Source: TfL, London Data Store",y="Bike rentals", x = element_blank())
```

```{r Chlng1_bike_by_week, warning=FALSE}
bike_weekly_avg<-bike%>%
  mutate(year_corrected=ifelse(month=="Jan"&(week==52|week==53), year-1, ifelse(month=="Dec"&(week==1), year+1, year)))%>%
  filter(year_corrected %in% c(2017, 2018, 2019, 2020, 2021, 2022))%>%
  group_by(year_corrected, week)%>%
  summarise(weekly_avg=mean(bikes_hired))%>%
  ungroup()

bike_weekly_avg_across_years<-bike%>%
  mutate(year_corrected=ifelse(month=="Jan"&(week==52|week==53), year-1, ifelse(month=="Dec"&(week==1), year+1, year)))%>%
  filter(year %in% c(2016, 2017, 2018, 2019))%>%
  group_by(week)%>%
  summarise(weekly_avg_across_years=mean(bikes_hired))%>%
  ungroup()

bike_weekly_avg <- bike_weekly_avg %>%
  inner_join(bike_weekly_avg_across_years, by = "week")%>%
mutate(weekly_change=weekly_avg/weekly_avg_across_years-1)

bike_weekly_avg
```

```{r Chlng1_plot2, warning=FALSE}
ggplot(bike_weekly_avg, aes(x=week))+geom_line(aes(y=weekly_change))+facet_wrap(~year_corrected, nrow=2)+scale_y_continuous(labels = scales::percent)+scale_x_continuous(breaks=c(13, 26, 39, 53))+theme(legend.position="none")+
  geom_braid(aes(ymin=0, ymax=weekly_change, fill=weekly_change>0))+
  geom_rect(data=bike_weekly_avg, aes(xmin=13, xmax=26, ymin=-Inf, ymax=Inf), color="transparent", fill="grey20",  alpha=0.005)+ 
  geom_rect(data=bike_weekly_avg, aes(xmin=39, xmax=53, ymin=-Inf, ymax=Inf), color="transparent", fill="grey20",  alpha=0.005)+geom_rug(mapping = aes(color = weekly_change>0), sides="b")+
  labs(title = "Weekly change in TfL bike rentals",
       subtitle = "% change from weekly averages calculated between 2016-2019", 
       caption = "Source: TfL, London Data Store",y=element_blank(), x = "Week")
```

For both of these graphs, you have to calculate the expected number of
rentals per week or month between 2016-2019 and then, see how each
week/month of 2020-2022 compares to the expected rentals. Think of the
calculation `excess_rentals = actual_rentals - expected_rentals`.

Should you use the mean or the median to calculate your expected
rentals? Why?

We use the mean to calculate expected rentals because according to the law of large numbers the sample mean approaches the expected value of a variable as the sample size grows infinitely large. This property makes the mean superior to median when it comes to calculating expected values. 

In creating your plots, you may find these links useful:

-   <https://ggplot2.tidyverse.org/reference/geom_ribbon.html>
-   <https://ggplot2.tidyverse.org/reference/geom_tile.html>
-   <https://ggplot2.tidyverse.org/reference/geom_rug.html>
